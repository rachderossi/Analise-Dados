---
title: iFood - Customer Segmentation
author: Raquel Rossi
date: "`r Sys.Date()`"
output: rmdformats::readthedown
code_folding: hide
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

library(rmarkdown)
library(rmdformats)
library(ggplot2)
library(rfm)
library(dplyr)
library(pander)
library(sqldf)
library(tidyverse)
library(highcharter)
library(RColorBrewer)
library(caTools)
library(e1071)
library(caret)
```

# Problem

The objective of the team is to build a predictive model that will produce the highest profit for the next direct marketing campaign, scheduled for the next month. The new campaign, sixth, aims at selling a new gadget to the Customer Database. To build the model, a pilot campaign involving 2.240 customers was carried out. The customers were selected at random and contacted by phone regarding the acquisition of the gadget. During the following months, customers who bought the offer were properly labeled. The total cost of the sample campaign was 6.720MU and the revenue generated by the customers who accepted the offer was 3.674MU. Globally the campaign had a profit of 3.046MU. The success rate of the campaign was 15%. The objective is of the team is to develop a model that predicts customer behavior and to apply it to the rest of the customer base. Hopefully, the model will allow the company to cherry pick the customers that are most likely to purchase the offer while leaving out the non respondents, making t he next campaign highly profitable. Moreover, other than maximizing the profit of the campaign, the CMO is interested in understanding to study the characteristic features of those customers who are willing to buy the gadget.

The data set contains sociodemographic and firmographic features about 2.240 customers who were contacted. Additionally, it contains a flag for those customers who responded the campaign, by buying the product.

- In this project, the RFM calculation is made in order to understand how customers should be classified.
- Afterwards a predictive classification model is made using the Naive Bayes algorithm.

```{r, include=FALSE}
setwd("C:/Users/Administrador/Desktop/Customer_Segmentation") # change
dados <- read.csv(file = 'ml_project1_data.csv')

summary(dados)
str(dados)
```

# RFM

```{r}
# value spent on products
dados$mont <- dados$MntFishProducts+dados$MntFruits+dados$MntGoldProds+
              dados$MntMeatProducts+dados$MntSweetProducts+dados$MntWines

# amount of purchases
dados$num <- dados$NumCatalogPurchases+dados$NumDealsPurchases+
             dados$NumStorePurchases+dados$NumWebPurchases

customers_RFM = sqldf(
    "SELECT ID,
            MIN(Recency) AS 'Recency',
            Sum(num) AS 'Frequency',
            SUM(mont) AS 'Monetary'
        FROM dados
        GROUP BY 1"
)

customers_RFM %>% 
  head(10) %>% 
      formattable::formattable()
```

# Histograms

To evaluate the distribution of the RFM parameters we can use the histogram.

```{r}
# Recency
ggplot(customers_RFM, aes(x = Recency)) +
        geom_histogram(aes(fill = ..count..), binwidth = 10) +
        scale_x_continuous(name = "Recency",
                           breaks = seq(0, 100, 10),
                           limits=c(0, 100)) +
        scale_y_continuous(name = "Count") +
        scale_fill_gradient(low="blue", high="red") + 
        ggtitle("Frequency of the amount of time since the last purchase")

# Frequency
ggplot(customers_RFM, aes(x = Frequency)) +
        geom_histogram(aes(fill = ..count..), binwidth = 5) +
        scale_x_continuous(name = "Frequency",
                           breaks = seq(0, 40, 5),
                           limits=c(0, 40)) +
        scale_y_continuous(name = "Count") +
        scale_fill_gradient(low="blue", high="red") + 
        ggtitle("Frequency of the amount of purchases made by the customer in the company")

# Monetary
ggplot(customers_RFM, aes(x = Monetary)) +
        geom_histogram(aes(fill = ..count..), binwidth = 100) +
        scale_x_continuous(name = "Monetary",
                           breaks = seq(0, 2500, 500),
                           limits=c(0, 2500)) +
        scale_y_continuous(name = "Count") +
        scale_fill_gradient(low="blue", high="red") + 
        ggtitle("Frequency of the amount of value spent by the customer in the company")
```

# Percentile

```{r}
quantile(customers_RFM$Recency, probs = seq(0, 1, 0.20)) %>% pander()
```

Analyzing how many days was the customer's last purchase, we can see that:

- Top20 customers bought in the last 19 days;
- The next 20% of customers bought between 19 and 39 days;
- Whereas the last 20% of customers spend more than 79 days without making any purchases.

```{r}
quantile(customers_RFM$Frequency, probs = seq(0, 1, 0.20)) %>% pander()
```

As for the frequency with which they make purchases, we can see that:

- Top20 customers bought more than 22 times over the period under review;
- The following 20% of customers bought between 17 and 22 times;
- The last 20% of customers bought 7 times in the period under review.

```{r}
quantile(customers_RFM$Monetary, probs = seq(0, 1, 0.20)) %>% pander()
```

As for the amount spent by the customer, we can see that:

- Top20 customers spend on average more than 1174.00 u.m (currency unit);
- The next 20% spend between 635.4 and 1174.00 u.m, while the last 20% of customers spend less than 55.00 u.m in their average consumption.

# RFM score

```{r}
rfm_data <- customers_RFM

rfm_data <-
    rfm_data %>%
    mutate(
        R = ntile(desc(Recency), 5),
        F = ntile(Frequency, 5),
        M = ntile(Monetary, 5)
    )

rfm_data$RFM <- rfm_data$R * 100 + rfm_data$F * 10 + rfm_data$M

rfm_data %>% 
  head(10) %>% 
      formattable::formattable()
```

Note that customers with a high RFM score have low values for the variable Recency and high for the variables Frequency and Monetary, for example ID = 25, while customers with a low RFM score, show high values for the variable Recency and high for Frequency, for example ID = 17. Being that, for customers with intermediate RFM score values they need a more careful analysis. As will be seen below.

# Customer Segmentation

```{r}
rfm_data$segment <- NA

rfm_data$segment[which(rfm_data$RFM == 111)] <- 'Lost'
rfm_data$segment[which(rfm_data$RFM > 111)] <- 'Hibernating'

rfm_data$segment[which(rfm_data$RFM >= 222)] <- 'About to sleep'

rfm_data$segment[which(rfm_data$RFM >= 333)] <- 'Potential loyalist'

rfm_data$segment[which(rfm_data$RFM >= 444)] <- 'Champion'


# 2nd round
rfm_data$segment[which(rfm_data$segment == 'Potential loyalist' &
                           (rfm_data$F >= 4))] <- 'Loyal customer'

rfm_data$segment[which(rfm_data$segment == 'About to sleep' &
                           (rfm_data$M >= 4))] <-'Needing attention'

rfm_data$segment[which(rfm_data$segment == 'Hibernating' &
                           (rfm_data$F >= 4 & rfm_data$M >= 4))] <-'Can not lose them'

rfm_data[, -c(5, 6,7)] %>% 
    head(10) %>% 
    formattable::formattable()
```

# Distribution of customers by segments

```{r}
rfm_data$segment <-
    factor(
        x = rfm_data$segment,
        levels = c(
            'Lost',
            'Hibernating',
            'Can not lose them',
            'About to sleep',
            'Needing attention',
            'New Customer',
            'Potential loyalist',
            'Loyal customer',
            'Champion'
        )
    )


# frequency table
freqTable <-
    rfm_data %>%
    # group_by(group) %>%
    count(segment) %>%
    # arrange(desc(n)) %>%
    rename(Segment = segment, Count = n)

freqTable %>% 
      formattable::formattable()


# or grouped
cust_aggr_dat <-
    aggregate(x = rfm_data[, 2:4],
              by = list(rfm_data$segment),
              mean)


cust_aggr_dat %>% 
      formattable::formattable()
```

The results show that:

- Champion customers (598), considered the most valuable customers spend an average of 743.00 u.m, made purchases more than 17 times and the last purchase was on average 14 days ago;
- While, the Lost case is the worst case for 88 days without making a purchase;
- The highlight goes to the segment Needing attention, since they have a high consumption, however the last activity was more than 2 months ago.

# Data visualization

```{r}
# tree map
hctreemap2(
    data = freqTable,
    group_vars = "Segment",
    size_var = "Count",
    color_var = "Count"
    )

# bar graph
highchart() %>%
    hc_add_series(
        data = freqTable,
        type = 'column',
        hcaes(x = Segment, y = Count),
        dataLabels = list(align = "center", enabled = TRUE,
                          style = list(
                                      fontWeight = "bold",
                                      color = "#f7a35c",
                                      textOutline = NULL
                                      )
                          ),
        name = 'Segments'
    ) %>%
    hc_xAxis(categories = unique(freqTable$Segment)) %>%
    hc_yAxis(title = list(text = "Clients"))
```

Customers in the Champions segment are considered to be the most valuable and About to sleep and Needing attention, need some special attention to rescue them.


```{r,  include=FALSE}
# data base for classification
setwd("C:/Users/Administrador/Desktop/Customer_Segmentation") # change
dados <- read.csv(file = 'ml_project1_data.csv')

# Removing some variables
dados$Z_CostContact = NULL
dados$Z_Revenue = NULL
dados$Dt_Customer = NULL

# Removing  NA from income variable
dados <- dados[!is.na(dados$Income),]

summary(dados)
str(dados)
```


```{r, include=FALSE}
# transforming categorical attributes, to be able to use the machine learning algorithm
table(dados$Education)
unique(dados$Education)
dados$Education <- factor(dados$Education, levels = c('2n Cycle','Basic', 'Graduation', 'Master', 'PhD'), labels = c(1,2,3,4,5))
dados[is.na(dados$Education)]


table(dados$Marital_Status)
unique(dados$Marital_Status)
dados$Marital_Status <- factor(dados$Marital_Status, levels = c('Single','Together', 'Married', 'Divorced', 'Widow', 'Alone', 'Absurd', 'YOLO'), 
                               labels = c(1,2,3,4,5,6,7,8))
dados[is.na(dados$Marital_Status)]

# transforming the variable of interest into a factor
dados$Response <- as.factor(as.numeric(dados$Response))
```


```{r, include=FALSE}
# scaling numeric attributes
dados [ , 2] = scale(dados [ , 2])
dados [ , 5:25] = scale(dados[ , 5:25])
```

```{r, include=FALSE}
#train and test
set.seed(1)
# 75% because the database is not that big
divisao = sample.split(dados$Response, SplitRatio = 0.75)

base_treinamento = subset(dados[-1], divisao == TRUE) 
base_teste = subset(dados[-1], divisao == FALSE) 
```

# Applying the Naive Bayes algorithm

```{r, include=FALSE}
classificador = naiveBayes(x = base_treinamento[-24], y = base_treinamento$Response)
predictions = predict(classificador, newdata = base_teste[-24])
```

I chose the Naive Bayes algorithm, because it disregards correlations between variables, treating each variable independently. This algorithm is also faster to implement than for example an SVM algorithm and in addition to not needing a lot of data to make the classification.

# Confusion Matrix

```{r}
matriz_confusao = table(base_teste[, 25], predictions)

confusionMatrix(matriz_confusao)
```

Analyzing the confusion matrix, in class 0 (customer did not buy the offer) the algorithm correctly classified 449 observations and incorrectly 22 observations, in class 1 (customer bought the offer) the algorithm correctly classified 67 observations and incorrectly 16 observations. In both classes, the algorithm was more than right.

Model accuracy was 93.14%.

# Making predictions

```{r, include=FALSE}
dados$predictions <- NULL
dados$predictions <- predictions
```

```{r}
dados[, -c(2:25)] %>% 
    head(28) %>% 
   pander()
```

Of the first 30 IDs (customers), 24 were classified correctly and 6 incorrectly.